{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############分别用随机森林、逻辑回归、MultinomialNB、SGD进行舆情学习#####\n",
    "############样本来自爬虫爬取的数据##########\n",
    "分析新闻正负情感值：\n",
    "读取新闻并且进行文本处理和分词\n",
    "建立模型 build_and_evaluate(X,y,classifier,outpath='model')\n",
    "采用了gridsearch， 允许同时运训多种参数同时进行\n",
    "也可以gridsearch = False 如果不需要调参数\n",
    "根据precision 和 recall 值， 对比Multibinomial, logistic regression, SGD等。最终采用随机森林 模型\n",
    "outpath 允许模型保存到本地\n",
    "用随机森林模型，得出每个词的重要性，也就是feature importance\n",
    "寻找对于模型预测最有决定性的文字：show_most_informative_features(model, text=None, n=20):\n",
    "这个function只适用于pipline结构，也就是在训练模型的时候，需要吧gridsearch关掉训练出来的模型才能用\n",
    "随机森里不可用\n",
    "会产出哪些词是正面导向和负面导向以及向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "np.random.seed(1337)\n",
    "import re\n",
    "import codecs\n",
    "import jieba\n",
    "import math\n",
    "import numpy as np\n",
    "from itertools import product, count  \n",
    "from heapq import nlargest  \n",
    "from gensim.models import word2vec  \n",
    "from sklearn.utils import shuffle\n",
    "try:\n",
    "    reload(sys)\n",
    "    sys.setdefaultencoding('utf-8')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(\"pos.JSON\", 'r') as fp:\n",
    "#     pos_text = json.load( fp)\n",
    "# with open(\"neg.JSON\", 'r') as fp:\n",
    "#     neg_text = json.load( fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_split(str_centence):\n",
    "    list_ret = list()\n",
    "    for s_str in str_centence.split('。'):\n",
    "        if '?' in s_str:\n",
    "            list_ret.extend(s_str.split('？'))\n",
    "        elif '!' in s_str:\n",
    "            list_ret.extend(s_str.split('！'))\n",
    "        else:\n",
    "            list_ret.append(s_str.strip())\n",
    "    return list_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordset = set()\n",
    "with open('sa/jieba_dict/stopwords.txt','r',encoding = 'utf-8') as sw:\n",
    "    for line in sw:\n",
    "        stopwordset.add(line.strip('\\n'))\n",
    "\n",
    "def seg_art_list(art_list):\n",
    "    corpus = []\n",
    "    for title, art in art_list.items():\n",
    "        corpus.append(\" \".join(seg_sent(art)))\n",
    "    \n",
    "    return corpus\n",
    "        \n",
    "output = open('word_seg.txt','w')\n",
    "def seg_sent(art):\n",
    "    r = '[’!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]+'  \n",
    "    art = art.strip()\n",
    "    art = re.sub(r, '', art)\n",
    "    art = re.sub(\"[a-z]\",\"\",art)\n",
    "    l = []\n",
    "\n",
    "    seg_list = list(jieba.cut(art, cut_all = False))\n",
    "    for word in seg_list:\n",
    "        if word not in stopwordset and word != ' ' and word != \"\\n\" and word != \"\\n\\n\":\n",
    "                output.write(word + ' ')\n",
    "                l.append(word)\n",
    "    return l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/nr/4rg65wr168q0jp4wjc2kkh100000gn/T/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2318\n",
      "348\n",
      "3755\n",
      "2568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 1.390 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "##vectorizer = TfidfVectorizer(sublinear_tf=True,  stop_words='english')\n",
    "\n",
    "import json\n",
    "# with open(\"pos.JSON\", 'r') as fp:\n",
    "#     pos_text = json.load( fp)\n",
    "# with open(\"neg.JSON\", 'r') as fp:\n",
    "#     neg_text = json.load( fp)\n",
    "\n",
    "#    title['fasf']= content\n",
    "\n",
    "with open(\"/Users/daichanglin/Desktop/data/pos0307.JSON\", 'r') as fp:\n",
    "    pos_text = json.load( fp)\n",
    "with open(\"/Users/daichanglin/Desktop/data/neg0307.JSON\", 'r') as fp:\n",
    "    neg_text = json.load( fp)\n",
    "     \n",
    "\n",
    "    \n",
    "# tl = u\"平安银行(000001)年报点评：不良加大处置 零售加快转型\"\n",
    "# if(tl in pos_text):\n",
    "#     print(pos_text[tl])\n",
    "    \n",
    "# # tl = \"物美掌权，业务有望稳中有进\"\n",
    "# # if(tl in neg_text):\n",
    "# #     print(neg_text[tl])\n",
    "    \n",
    "# print(len(pos_text.items()))\n",
    "# print(\"add after\")\n",
    "# for title, art in new_pos_text.items():\n",
    "#     print(title)\n",
    "#     pos_text[title]=art\n",
    "# print(len(pos_text.items()))\n",
    "# tl = u\"平安银行(000001)年报点评：不良加大处置 零售加快转型\"\n",
    "# if(tl in pos_text):\n",
    "#     print(pos_text[tl])\n",
    "    \n",
    "# tl = \"物美掌权，业务有望稳中有进\"\n",
    "# if(tl in neg_text):\n",
    "#     print(neg_text[tl])\n",
    "\n",
    "print(len(pos_text))\n",
    "print(len(neg_text))\n",
    "\n",
    "negfile = \"/Users/daichanglin/Desktop/igoldenbeta/robotSVN/robot/robot-parent/python/data/negfactor.txt\"\n",
    "i=0\n",
    "with open(negfile,'r',encoding = 'utf-8') as sw:\n",
    "    for line in sw:\n",
    "        neg_text[\"neg\"+str(i)]=line\n",
    "        i=i+1\n",
    "        \n",
    "posfile = \"/Users/daichanglin/Desktop/igoldenbeta/robotSVN/robot/robot-parent/python/data/posfactor.txt\"\n",
    "i=0\n",
    "with open(posfile,'r',encoding = 'utf-8') as sw:\n",
    "    for line in sw:\n",
    "        pos_text[\"pos\"+str(i)]=line\n",
    "        i=i+1\n",
    "        \n",
    "print(len(pos_text))\n",
    "print(len(neg_text))\n",
    "\n",
    "pos_tfidf = seg_art_list(pos_text)\n",
    "neg_tfidf = seg_art_list(neg_text)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pos_tfidf0307.JSON\", 'w') as fp:\n",
    "    json.dump(pos_tfidf, fp)\n",
    "with open(\"neg_tfidf0307.JSON\", 'w') as fp:\n",
    "    json.dump(neg_tfidf, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import operator\n",
    "from time import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report as clsr\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cross_validation import train_test_split as tts\n",
    "import timeit\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#96条正面，123 条负面\n",
    "X = list(pos_tfidf) + list(neg_tfidf)\n",
    "y = [1] * len(pos_tfidf) + [-1]*len(neg_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n",
      "3755\n",
      "2568\n",
      "6323\n",
      "6323\n"
     ]
    }
   ],
   "source": [
    "print(\"finish\")\n",
    "print(len(pos_tfidf))\n",
    "print(len(neg_tfidf))\n",
    "print(len(X))\n",
    "print(len(y))\n",
    "# print(X[0:2])\n",
    "# print(y[0:2])\n",
    "\n",
    "# finish\n",
    "# 2318\n",
    "# 348\n",
    "# 2666\n",
    "# 2666\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test\n",
    "# iniData = False\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)\n",
    "len(X_train)\n",
    "# print(x)\n",
    "\n",
    "def build_and_evaluate(X, y, classifier=SGDClassifier,outpath = False, grid_Search = True):\n",
    "\n",
    "    def build(classifier, X, y=None):\n",
    "        \"\"\"\n",
    "        Inner build function that builds a single model.\n",
    "        \"\"\"\n",
    "        if isinstance(classifier, type):\n",
    "            classifier = classifier()\n",
    "        if grid_Search:\n",
    "            parameters = {'vect__max_df': (0.5, 0.75, 1.0),\n",
    "                        #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "                        'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "                        'tfidf__use_idf': (True, False),\n",
    "                        'tfidf__norm': ('l1', 'l2'),\n",
    "                        #'clf__alpha': (0.00001, 0.000001),\n",
    "                        #'clf__penalty': ('l2', 'elasticnet'),\n",
    "                         #'clf__n_iter': (10, 50, 80),\n",
    "                }\n",
    "\n",
    "            pipeline = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', classifier),])\n",
    "            grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "            print(\"Performing grid search...\")\n",
    "            print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "            print(\"parameters:\")\n",
    "            print(parameters)\n",
    "            t0 = time()\n",
    "            grid_search.fit(X, y)\n",
    "            print(\"done in %0.3fs\" % (time() - t0))\n",
    "            print()\n",
    "\n",
    "            print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "            print(\"Best parameters set:\")\n",
    "            best_parameters = grid_search.best_estimator_.get_params()\n",
    "            for param_name in sorted(parameters.keys()):\n",
    "                print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "            #model.fit(X, y)\n",
    "            return grid_search\n",
    "        else:\n",
    "            pipeline = Pipeline([('vect', CountVectorizer(ngram_range=(1,1),min_df=10,max_df = 0.9)),\n",
    "                                 ('tfidf', TfidfTransformer()),('clf', classifier),])\n",
    "            t0 = time()\n",
    "            pipeline.fit(X, y)\n",
    "\n",
    "            print(\"done in %0.3fs\" % (time() - t0))\n",
    "            return pipeline\n",
    "    # Begin evaluation\n",
    "\n",
    "\n",
    "    labels = LabelEncoder()\n",
    "\n",
    "    y = labels.fit_transform(y)\n",
    "\n",
    "    print(\"Building for evaluation\")\n",
    "#     X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)\n",
    "#     if(iniData==False):\n",
    "#         X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)\n",
    "#         iniData = True\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)\n",
    "    model = build(classifier, X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"classifier result:\")\n",
    "    print(clsr(y_test, y_pred, target_names=['neg', 'pos']))\n",
    "    if outpath:\n",
    "        with open(outpath, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "        print(\"Model written out to {}\".format(outpath))\n",
    "    print(\"confusion matrix\")\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building for evaluation\n",
      "done in 0.953s\n",
      "classifier result:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.96      0.86      0.91       542\n",
      "        pos       0.90      0.98      0.94       723\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1265\n",
      "\n",
      "Model written out to model_nb\n",
      "confusion matrix\n",
      "[[466  76]\n",
      " [ 17 706]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier=MultinomialNB\n",
    "\n",
    "model_Mb = build_and_evaluate(X,y,classifier,outpath='model_nb', grid_Search=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归&信贷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building for evaluation\n",
      "check_X_y\n",
      "[1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, 1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, 1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, -1, -1, 1, -1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1, 1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, -1, 1, -1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, -1, 1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, -1, -1, 1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, 1, -1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1]\n",
      "done in 1.287s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier result:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       1.00      0.93      0.96       542\n",
      "        pos       0.95      1.00      0.98       723\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1265\n",
      "\n",
      "Model written out to model_lr\n",
      "confusion matrix\n",
      "[[506  36]\n",
      " [  1 722]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier= LogisticRegression\n",
    "model_Lr = build_and_evaluate(X,y,classifier,outpath='model_lr',grid_Search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building for evaluation\n",
      "check_X_y\n",
      "[1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, 1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, 1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, -1, -1, 1, -1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1, 1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, -1, 1, -1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, -1, 1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, -1, -1, 1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, 1, -1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1]\n",
      "done in 1.205s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier result:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       1.00      0.93      0.96       542\n",
      "        pos       0.95      1.00      0.98       723\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1265\n",
      "\n",
      "Model written out to model\n",
      "confusion matrix\n",
      "[[506  36]\n",
      " [  1 722]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier= LogisticRegression\n",
    "\n",
    "model_Lr = build_and_evaluate(X,y,classifier,outpath='model',grid_Search=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building for evaluation\n",
      "done in 0.905s\n",
      "classifier result:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.99      0.98      0.98       542\n",
      "        pos       0.98      0.99      0.99       723\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1265\n",
      "\n",
      "Model written out to model_SGD\n",
      "confusion matrix\n",
      "[[530  12]\n",
      " [  5 718]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier= SGDClassifier\n",
    "model_default = build_and_evaluate(X,y,outpath='model_SGD',grid_Search=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building for evaluation\n",
      "done in 8.563s\n",
      "classifier result:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.99      0.91      0.95       542\n",
      "        pos       0.94      0.99      0.97       723\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1265\n",
      "\n",
      "Model written out to model0607_rf\n",
      "confusion matrix\n",
      "[[495  47]\n",
      " [  5 718]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier= RandomForestClassifier(n_estimators=500,min_samples_leaf=2)\n",
    "\n",
    "model_RF = build_and_evaluate(X,y,classifier,outpath='model0607_rf',grid_Search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "负面\t\t 正面\n",
      "[[ 0.81782449  0.18217551]\n",
      " [ 0.96708653  0.03291347]\n",
      " [ 0.83584196  0.16415804]\n",
      " [ 0.77410071  0.22589929]\n",
      " [ 0.88186226  0.11813774]\n",
      " [ 0.89648983  0.10351017]\n",
      " [ 0.91399837  0.08600163]\n",
      " [ 0.82079407  0.17920593]\n",
      " [ 0.73295685  0.26704315]\n",
      " [ 0.87347313  0.12652687]]\n",
      "[[ 0.05964444  0.94035556]\n",
      " [ 0.1248453   0.8751547 ]\n",
      " [ 0.14195108  0.85804892]\n",
      " [ 0.17514497  0.82485503]\n",
      " [ 0.45551986  0.54448014]\n",
      " [ 0.09201905  0.90798095]\n",
      " [ 0.0281      0.9719    ]\n",
      " [ 0.03308658  0.96691342]\n",
      " [ 0.0306      0.9694    ]\n",
      " [ 0.12696136  0.87303864]]\n"
     ]
    }
   ],
   "source": [
    "print('负面\\t\\t','正面')\n",
    "print(model_RF.predict_proba(neg_tfidf[10:20]))\n",
    "print(model_RF.predict_proba(pos_tfidf[10:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99865237,  0.00134763],\n",
       "       [ 0.94657015,  0.05342985],\n",
       "       [ 0.99650224,  0.00349776],\n",
       "       [ 0.93971509,  0.06028491],\n",
       "       [ 0.81209   ,  0.18791   ],\n",
       "       [ 0.88944153,  0.11055847],\n",
       "       [ 0.99397411,  0.00602589],\n",
       "       [ 0.81503642,  0.18496358],\n",
       "       [ 0.60603066,  0.39396934],\n",
       "       [ 0.94665958,  0.05334042]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Lr.predict_proba(neg_tfidf[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99660067,  0.00339933],\n",
       "       [ 0.99376394,  0.00623606],\n",
       "       [ 0.98004583,  0.01995417],\n",
       "       [ 0.93325027,  0.06674973],\n",
       "       [ 0.49872323,  0.50127677],\n",
       "       [ 0.97111486,  0.02888514],\n",
       "       [ 0.99844626,  0.00155374],\n",
       "       [ 0.18555475,  0.81444525],\n",
       "       [ 0.03020401,  0.96979599],\n",
       "       [ 0.97748797,  0.02251203]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Mb.predict_proba(neg_tfidf[10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 几个模型的训练结果是随机森林效果最佳"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最有决定性的文字：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 这个需要grid_searhch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_most_informative_features(model, text=None, n=100):\n",
    "    # Extract the vectorizer and the classifier from the pipeline\n",
    "    vectorizer = model.named_steps['vect']\n",
    "    classifier = model.named_steps['clf']\n",
    "\n",
    "    # Check to make sure that we can perform this computation\n",
    "    if not hasattr(classifier, 'coef_'):\n",
    "        raise TypeError(\n",
    "            \"Cannot compute most informative features on {}.\".format(\n",
    "                classifier.__class__.__name__\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if text is not None:\n",
    "        # Compute the coefficients for the text\n",
    "        tvec = model.transform([text]).toarray()\n",
    "    else:\n",
    "        # Otherwise simply use the coefficients\n",
    "        tvec = classifier.coef_\n",
    "\n",
    "    # Zip the feature names with the coefs and sort\n",
    "    coefs = sorted(\n",
    "        zip(tvec[0], vectorizer.get_feature_names()),\n",
    "        key=operator.itemgetter(0), reverse=True\n",
    "    )\n",
    "\n",
    "    # Get the top n and bottom n coef, name pairs\n",
    "    topn  = zip(coefs[:n], coefs[:-(n+1):-1])\n",
    "\n",
    "    # Create the output string to return\n",
    "    output = []\n",
    "\n",
    "    # If text, add the predicted value to the output.\n",
    "    if text is not None:\n",
    "        output.append(\"\\\"{}\\\"\".format(text))\n",
    "        output.append(\n",
    "            \"Classified as: {}\".format(model.predict([text]))\n",
    "        )\n",
    "        output.append(\"\")\n",
    "\n",
    "    # Create two columns with most negative and most positive features.\n",
    "    for (cp, fnp), (cn, fnn) in topn:\n",
    "        output.append(\n",
    "            \"{:0.4f}{: >15}    {:0.4f}{: >15}\".format(\n",
    "                cp, fnp, cn, fnn\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  importance\n",
      "2238    增持    0.195328\n",
      "4500    辞职    0.063002\n",
      "1632    减持    0.052872\n",
      "1562    关于    0.025342\n",
      "2971    持股    0.015173\n",
      "4290    计划    0.015059\n",
      "1107    中性    0.014017\n",
      "4819    预计    0.011886\n",
      "2396    完成    0.011630\n",
      "1301    以上    0.010797\n",
      "4836    风险    0.010086\n",
      "3028    提示    0.009226\n",
      "4324    评级    0.008670\n",
      "296   2017    0.008211\n",
      "1274    亿元    0.008130\n",
      "4813    预期    0.007906\n",
      "1542  公司股票    0.007896\n",
      "4068    维持    0.007820\n",
      "2246    增长    0.007713\n",
      "1660    分别    0.006716\n",
      "2458    对应    0.006598\n",
      "4552    进展    0.006478\n",
      "932     一致    0.006351\n",
      "2919    投资    0.006340\n",
      "3766    监事    0.006307\n",
      "4227    行动    0.006167\n",
      "3024    提升    0.005882\n",
      "4222    行业    0.005850\n",
      "3264    有望    0.005619\n",
      "2551    市场    0.005595\n",
      "...    ...         ...\n",
      "1929  去年同期    0.000142\n",
      "1171    乐普    0.000142\n",
      "827    asp    0.000142\n",
      "2176    地位    0.000141\n",
      "3303    本期    0.000141\n",
      "2152    国家    0.000140\n",
      "337     21    0.000140\n",
      "86      08    0.000139\n",
      "4569    迹象    0.000139\n",
      "3251   有利于    0.000139\n",
      "1109    中报    0.000138\n",
      "909     一定    0.000138\n",
      "1007   下半年    0.000137\n",
      "1758    力度    0.000137\n",
      "1806    北京    0.000137\n",
      "3691    生物    0.000136\n",
      "3057    收窄    0.000135\n",
      "4047    结构    0.000135\n",
      "2489    尚未    0.000134\n",
      "2785    恢复    0.000134\n",
      "898    yoy    0.000133\n",
      "2041    合计    0.000132\n",
      "4024    终端    0.000132\n",
      "1216    交易    0.000131\n",
      "4219    融资    0.000131\n",
      "3685    生态    0.000130\n",
      "3645    环境    0.000130\n",
      "2116   四季度    0.000129\n",
      "2756    快递    0.000128\n",
      "996     上涨    0.000128\n",
      "\n",
      "[500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import pandas\n",
    "# classifier= RandomForestClassifier(n_estimators=20,random_state=5,min_samples_leaf=2)\n",
    "# model_MRF = build_and_evaluate(X,y,classifier,outpath='model',grid_Search=False)\n",
    "# #   pipeline = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', classifier),])\n",
    "# tfidf = model_MRF.named_steps['tfidf']       \n",
    "# feature_names = list(tfidf.get_feature_names())\n",
    "        \n",
    "# importances = pandas.DataFrame({'name':feature_names,'imp':model_MRF.feature_importances_\n",
    "#                             }).sort(['imp'], ascending = False).reset_index(drop = True)\n",
    "\n",
    "# importances.head(100)\n",
    "\n",
    "# words = show_most_informative_features(model_MRF)\n",
    "# print(words)\n",
    "\n",
    "\n",
    "# tfidf =  model_RF.named_steps['tfidf']\n",
    "vectorizer = model_RF.named_steps['vect']\n",
    "classifier = model_RF.named_steps['clf']\n",
    "feature_names = list(vectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "feature_importance = pd.DataFrame({'name':feature_names, 'importance':classifier.feature_importances_},columns = ['name','importance'])\n",
    "sort_importance = feature_importance.sort_values(by= ['importance'],ascending = False)\n",
    "print(sort_importance.head(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.1876             增持    -10.1457             遭到\n",
      "-4.4160             关于    -10.1457             选举\n",
      "-4.9259             计划    -10.1457             辞职\n",
      "-5.1720             亿元    -10.1457             轮候\n",
      "-5.1736             增长    -10.1457             补选\n",
      "-5.3056             进展    -10.1457           职工代表\n",
      "-5.5072             业务    -10.1457             冻结\n",
      "-5.5137             同比    -10.1457           保留意见\n",
      "-5.5322           2017    -10.1457         1q2017\n",
      "-5.6019             完成    -10.1180             聘任\n",
      "-5.7545             产品    -10.1054             平仓\n",
      "-5.7657             实现    -10.1007             秘书\n",
      "-5.7809            净利润    -10.0774         4q2016\n",
      "-5.7810             业绩    -10.0628             逾期\n",
      "-5.7866             预计    -10.0457             总裁\n",
      "-5.8727             分别    -10.0408            监事会\n",
      "-5.8955             有望    -10.0351             纠纷\n",
      "-5.9051             市场    -10.0170             离职\n",
      "-5.9097             行业    -10.0071             事务\n",
      "-5.9114             项目    -9.9630             增补\n",
      "-5.9229             提升    -9.9565             主席\n",
      "-5.9441             收入    -9.9546           2q17\n",
      "-5.9475             行动    -9.9169            003\n",
      "-5.9492             预期    -9.9122             仍存\n",
      "-5.9535             一致    -9.8955             违约\n",
      "-5.9688             我们    -9.8918             中性\n",
      "-6.0372             发展    -9.8892             处罚\n",
      "-6.0502           公司股票    -9.8878             账户\n",
      "-6.0879             风险    -9.8836           银行借款\n",
      "-6.0880             实施    -9.8826             刚性\n",
      "-6.1086             增速    -9.8738             迹象\n",
      "-6.1095             未来    -9.8712          2017e\n",
      "-6.1297             投资    -9.8665             显着\n",
      "-6.1614             产能    -9.8642             节约\n",
      "-6.1710           2018    -9.8637           财务总监\n",
      "-6.2147             盈利    -9.8597             略降\n",
      "-6.2282             持续    -9.8583             注销\n",
      "-6.2500             维持    -9.8532       20162018\n",
      "-6.2590             评级    -9.8466            调整期\n",
      "-6.2766             主要    -9.8451            充足率\n",
      "-6.3072             国内    -9.8434            724\n",
      "-6.3154             集团    -9.8397           财务指标\n",
      "-6.3217             归母    -9.8365             触及\n",
      "-6.3219             万吨    -9.8348             差额\n",
      "-6.3862             领域    -9.8343             谋求\n",
      "-6.3872             达到    -9.8325           环境影响\n",
      "-6.3903             继续    -9.8317            负责人\n",
      "-6.3990             科技    -9.8305             并非\n",
      "-6.4008            提示性    -9.8263           流动资产\n",
      "-6.4233             目前    -9.8257             交叉\n",
      "-6.4438             万元    -9.8242           平均价格\n",
      "-6.4682             销售    -9.8199             偏好\n",
      "-6.4703             对应    -9.8183            公司债\n",
      "-6.5087             营业    -9.8182             价齐\n",
      "-6.5139             结果    -9.8155            867\n",
      "-6.5261             布局    -9.8150             调节\n",
      "-6.5555             价格    -9.8136             过半\n",
      "-6.5610             收购    -9.8117            936\n",
      "-6.5658             补充    -9.8091             较差\n",
      "-6.5693             17    -9.8072           rnav\n",
      "-6.5720             同时    -9.8062            736\n",
      "-6.5820             预测    -9.8057             同降\n",
      "-6.5849             汽车    -9.8053             3q\n",
      "-6.5864             需求    -9.8045            铁矿石\n",
      "-6.5921             通过    -9.8013             8x\n",
      "-6.5922             优势    -9.8006             中南\n",
      "-6.5974             能力    -9.7991            268\n",
      "-6.5995            三季度    -9.7968             快捷\n",
      "-6.6031             电子    -9.7947             网上\n",
      "-6.6063             营收    -9.7925            512\n",
      "-6.6262             客户    -9.7914            431\n",
      "-6.6335             企业    -9.7909             真实\n",
      "-6.6367             研发    -9.7890           恢复正常\n",
      "-6.6515             规模    -9.7876             工资\n",
      "-6.6745             订单    -9.7875           绝大部分\n",
      "-6.6758             pe    -9.7866             操作\n",
      "-6.6793             第一    -9.7855             一条\n",
      "-6.6849             医疗    -9.7848            691\n",
      "-6.6916             以上    -9.7819            001\n",
      "-6.6933             股权    -9.7815           16q4\n",
      "-6.6958             影响    -9.7804             当季\n",
      "-6.6982             渠道    -9.7780            418\n",
      "-6.6991            eps    -9.7776            805\n",
      "-6.7041           2016    -9.7771             拆分\n",
      "-6.7179             品牌    -9.7771            副总裁\n",
      "-6.7192             提示    -9.7755             改增\n",
      "-6.7225             受益    -9.7729             着手\n",
      "-6.7246             技术    -9.7726             南洋\n",
      "-6.7246            进一步    -9.7726            管理费\n",
      "-6.7274             设备    -9.7704             人寿\n",
      "-6.7317             中国    -9.7671           有所提高\n",
      "-6.7410             空间    -9.7643           2600\n",
      "-6.7423             下降    -9.7641             负面\n",
      "-6.7454            毛利率    -9.7634             大国\n",
      "-6.7493             大幅    -9.7623            934\n",
      "-6.7496             资产    -9.7622             票据\n",
      "-6.7526             不及    -9.7621           9m17\n",
      "-6.8024             服务    -9.7614            资本化\n",
      "-6.8053             平台    -9.7612            372\n",
      "-6.8147             给予    -9.7611             折现\n"
     ]
    }
   ],
   "source": [
    "words_Mb = show_most_informative_features(model_Mb)\n",
    "print(words_Mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9572             增持    -8.0440             减持\n",
      "3.0748           2017    -7.1368             辞职\n",
      "2.5332             增长    -5.3061             中性\n",
      "2.1194             有望    -2.9496             冻结\n",
      "1.7797             预计    -2.5972           2016\n",
      "1.7282           2018    -2.3951           2015\n",
      "1.6469             项目    -2.2834             诉讼\n",
      "1.6131             产品    -2.1651             平仓\n",
      "1.5777             增速    -2.0196             离职\n",
      "1.5124             国内    -1.9367             质押\n",
      "1.4946             行业    -1.7758             监事\n",
      "1.4790            三季度    -1.7279            上半年\n",
      "1.4654             分别    -1.6985           1h17\n",
      "1.4526           公司股票    -1.6979             涉及\n",
      "1.4460             完成    -1.5688             下降\n",
      "1.4293             提升    -1.5664       20162018\n",
      "1.4024             持续    -1.4743             持股\n",
      "1.3917             计划    -1.4130            毛利率\n",
      "1.3508             万吨    -1.3998             独立\n",
      "1.3394             龙头    -1.3904             处罚\n",
      "1.2970             环比    -1.3609             会计\n",
      "1.1688             产能    -1.3411           保留意见\n",
      "1.1638             订单    -1.2987             下调\n",
      "1.1561             空间    -1.2723             16\n",
      "1.1359             汽车    -1.2680             同比\n",
      "1.1350             预期    -1.2492             快递\n",
      "1.1123             推荐    -1.2218            百分点\n",
      "1.0764             买入    -1.2083             意见\n",
      "1.0359             18    -1.2020            费用率\n",
      "1.0299             中国    -1.1820            证监会\n",
      "1.0258             业务    -1.1261           副总经理\n",
      "1.0156             风险    -1.1080             秘书\n",
      "0.9892             规模    -1.0859             减少\n",
      "0.9845             市场    -1.0552             以上\n",
      "0.9826            进一步    -1.0528             轮候\n",
      "0.9819             发展    -1.0442            董事会\n",
      "0.9761             布局    -0.9958            特高压\n",
      "0.9727             对应    -0.9849             聘任\n",
      "0.9601             投资    -0.9677           2q17\n",
      "0.9569             同时    -0.9458             亏损\n",
      "0.9542             客户    -0.9436            asp\n",
      "0.9324             17    -0.9184             事务\n",
      "0.9286             优势    -0.9120            一季度\n",
      "0.9200             酒店    -0.9047             家化\n",
      "0.9054             进入    -0.8941             补选\n",
      "0.9050             受益    -0.8731             纠纷\n",
      "0.8985             达到    -0.8571             停牌\n",
      "0.8951             合作    -0.8474             压力\n",
      "0.8813             补充    -0.8390             代表\n",
      "0.8736             显著    -0.8240             上升\n",
      "0.8687             不及    -0.8065             遭到\n",
      "0.8687             能力    -0.8060           财务总监\n",
      "0.8548             业绩    -0.7927            房地产\n",
      "0.8394             设备    -0.7862             披露\n",
      "0.8378             领域    -0.7704             司法\n",
      "0.8343             全球    -0.7401             贷款\n",
      "0.8175             第一    -0.7325           国企改革\n",
      "0.8170             根据    -0.7015             财务\n",
      "0.8070             一致    -0.6919            负责人\n",
      "0.7896             成为    -0.6852             关注\n",
      "0.7878             平台    -0.6808             3q\n",
      "0.7856             随着    -0.6759             未达\n",
      "0.7766             旅游    -0.6531             平米\n",
      "0.7583             服务    -0.6468            yoy\n",
      "0.7553             通过    -0.6460             st\n",
      "0.7510             零售    -0.6428            监事会\n",
      "0.7451             事件    -0.6271             信用\n",
      "0.7439             南京    -0.6232             公布\n",
      "0.7306             快报    -0.6148             出现\n",
      "0.7294             医院    -0.6115             折合\n",
      "0.7292             加速    -0.6107             较为\n",
      "0.7190             行动    -0.5920             高级\n",
      "0.7188             问询    -0.5860           管理人员\n",
      "0.7117             数据    -0.5834             触及\n",
      "0.7087             员工    -0.5832             由于\n",
      "0.7045       20172019    -0.5777           1573\n",
      "0.7042             扩张    -0.5772           职工代表\n",
      "0.6995             开始    -0.5754             逾期\n",
      "0.6955             维持    -0.5708             届满\n",
      "0.6882            半导体    -0.5652             上年\n",
      "0.6874             提示    -0.5642             主席\n",
      "0.6830             超过    -0.5588             同降\n",
      "0.6734             医疗    -0.5584            铁矿石\n",
      "0.6728             签订    -0.5534             注销\n",
      "0.6720             包括    -0.5465             持有\n",
      "0.6718           1719    -0.5448             tp\n",
      "0.6682             金科    -0.5372           9m17\n",
      "0.6681             保持    -0.5351             债务\n",
      "0.6672             盈利    -0.5179             激烈\n",
      "0.6662             复星    -0.5161             终止\n",
      "0.6636             天目    -0.5107             违约\n",
      "0.6423            原材料    -0.4976       20162017\n",
      "0.6307             娱乐    -0.4931             降低\n",
      "0.6289             材料    -0.4879           同比增加\n",
      "0.6281             生产    -0.4843             导致\n",
      "0.6246             品种    -0.4806             变动\n",
      "0.6211             核心    -0.4798             债券\n",
      "0.6136             光伏    -0.4774             调整\n",
      "0.6135             逐步    -0.4715             银行\n",
      "0.6117             免税    -0.4659             转型\n"
     ]
    }
   ],
   "source": [
    "words_Lr = show_most_informative_features(model_Lr)\n",
    "print(words_Lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.7829             增持    -8.4829             中性\n",
      "2.4511           2017    -3.7093             辞职\n",
      "1.9163             增速    -3.4770             减持\n",
      "1.8946             推荐    -2.6554           2016\n",
      "1.7738            三季度    -2.2863           2015\n",
      "1.6567           2018    -2.2855       20162018\n",
      "1.4513             买入    -2.0567            上半年\n",
      "1.3967             分别    -1.8135           1h17\n",
      "1.3659             环比    -1.7969             16\n",
      "1.2255             项目    -1.7378             平仓\n",
      "1.2219             龙头    -1.6685             离职\n",
      "1.1808           4q17    -1.6122           2q17\n",
      "1.1654             18    -1.5751             快递\n",
      "1.1356           1719    -1.4469            asp\n",
      "1.1308             动力    -1.4461             冻结\n",
      "1.1284             提升    -1.3439            一季度\n",
      "1.1231             有望    -1.3235             t2\n",
      "1.1088         201819    -1.3189            特高压\n",
      "1.1086            进一步    -1.2642             持有\n",
      "1.0888             持续    -1.2211             贷款\n",
      "1.0841             熊猫    -1.1607           1573\n",
      "1.0601             国内    -1.1465            yoy\n",
      "1.0601             万吨    -1.1403             同降\n",
      "1.0567             达到    -1.1300             下调\n",
      "1.0476             酒店    -1.1247             同增\n",
      "1.0433             苏宁    -1.1114             3q\n",
      "1.0370             累计    -1.1049             诉讼\n",
      "1.0339             谨慎    -1.0934             较为\n",
      "1.0288             预计    -1.0869       20162017\n",
      "1.0142             显著    -1.0647             涉及\n",
      "1.0118       20182020    -1.0511            毛利率\n",
      "1.0111             空间    -1.0261          2017e\n",
      "1.0107             判断    -1.0240             停牌\n",
      "1.0054             利率    -1.0145           国企改革\n",
      "0.9951             随着    -1.0138            房地产\n",
      "0.9932            发动机    -1.0040             合理\n",
      "0.9708             开始    -0.9877            suv\n",
      "0.9687             天目    -0.9869           9m17\n",
      "0.9660             签订    -0.9761             家化\n",
      "0.9608             包括    -0.9624             信用\n",
      "0.9533             增长    -0.9500             pb\n",
      "0.9380             能力    -0.9472             同比\n",
      "0.9247             提示    -0.9462             压力\n",
      "0.9176             视频    -0.9129             容量\n",
      "0.9126             水电    -0.9101             由于\n",
      "0.9088             风险    -0.9003             联合\n",
      "0.9023           2020    -0.8800             公布\n",
      "0.9001            胰岛素    -0.8730            386\n",
      "0.8992             零售    -0.8643             摘要\n",
      "0.8948             内容    -0.8586             天然\n",
      "0.8786             平均    -0.8579           电子商务\n",
      "0.8715             南京    -0.8569             08\n",
      "0.8675             中国    -0.8530             质押\n",
      "0.8639             对应    -0.8529             平米\n",
      "0.8633             快报    -0.8504           rpar\n",
      "0.8554             成为    -0.8390            peg\n",
      "0.8426             事件    -0.8360           金融服务\n",
      "0.8248             无线    -0.8255           公司业绩\n",
      "0.8158             营收    -0.8100             激烈\n",
      "0.8054             问询    -0.8090             优惠\n",
      "0.8050             基金    -0.8078           同比增加\n",
      "0.8024             扩张    -0.8059             定增\n",
      "0.8021             进入    -0.7929           中小企业\n",
      "0.8001             旅游    -0.7928             出台\n",
      "0.7897            压缩机    -0.7926           cagr\n",
      "0.7847             啤酒    -0.7879           不良贷款\n",
      "0.7827             金属    -0.7839             观察\n",
      "0.7767           解决方案    -0.7777             山西\n",
      "0.7760             生息    -0.7745             影响\n",
      "0.7742             汽车    -0.7707            二季度\n",
      "0.7726            不良率    -0.7576             关注\n",
      "0.7596             疗法    -0.7576           17h1\n",
      "0.7578         2017q3    -0.7574             细胞\n",
      "0.7565             对于    -0.7481             60\n",
      "0.7514             腾讯    -0.7474             21\n",
      "0.7512             订单    -0.7445             存在\n",
      "0.7487             根据    -0.7374             系统\n",
      "0.7473             林洋    -0.7339             逾期\n",
      "0.7456             13    -0.7284           利息支出\n",
      "0.7456             车载    -0.7238             注销\n",
      "0.7425             索道    -0.7102           产业布局\n",
      "0.7386             趋势    -0.6997             债务\n",
      "0.7339             规模    -0.6983             图形\n",
      "0.7308             分红    -0.6942             存储\n",
      "0.7282             幅度    -0.6786             折合\n",
      "0.7265             核电    -0.6753             会计\n",
      "0.7256            自动化    -0.6746         1h2017\n",
      "0.7255             品种    -0.6737             表示\n",
      "0.7253             计划    -0.6733             影业\n",
      "0.7233             发力    -0.6677            分公司\n",
      "0.7215             优势    -0.6660             万台\n",
      "0.7203             大连    -0.6645             产量\n",
      "0.7111             通过    -0.6637             减少\n",
      "0.7084             上市    -0.6616             回购\n",
      "0.7084            五粮液    -0.6602            农产品\n",
      "0.7077             受益    -0.6589       20171819\n",
      "0.7048             合计    -0.6416            费用率\n",
      "0.6968            天然气    -0.6314             矿区\n",
      "0.6908             要点    -0.6295             录得\n",
      "0.6907             预期    -0.6288            中青旅\n"
     ]
    }
   ],
   "source": [
    "model_default = show_most_informative_features(model_default)\n",
    "print(model_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
