{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############通过训练的模型进行分类（利好／利空，好坏）############     \n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import jieba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=10,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        stri...mators=500, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = pickle.load(open('sa/model','rb'))\n",
    "# outpath='model0607withFactor'\n",
    "# outpath='model0307'\n",
    "outpath='model0607_rf'\n",
    "\n",
    "model = pickle.load(open(outpath,'rb'))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordset = set()\n",
    "with open('sa/jieba_dict/stopwords.txt','r',encoding = 'utf-8') as sw:\n",
    "    for line in sw:\n",
    "        stopwordset.add(line.strip('\\n'))\n",
    "        \n",
    "def seg_sent(art):\n",
    "    r = '[’!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]+'  \n",
    "    art = art.strip()\n",
    "    art = re.sub(r, '', art)\n",
    "    l = []\n",
    "    seg_list = list(jieba.cut(art, cut_all = False))\n",
    "    for word in seg_list:\n",
    "        if word not in stopwordset and word != ' ' and word != \"\\n\" and word != \"\\n\\n\":\n",
    "            l.append(word)\n",
    "    corpus = \" \".join(l)\n",
    "    return corpus\n",
    "\n",
    "        \n",
    "def predictForConttent(content):\n",
    "    cp = seg_sent(content)\n",
    "    result = model.predict([cp])\n",
    "#     output = open('file_sa.txt','w')\n",
    "    rate = model.predict_proba([cp])\n",
    "    print(rate)\n",
    "   \n",
    "#     output.write(\"负面值2：\"+str(rate[0][0])+\" 正面值2： \"+str(rate[0][1]))\n",
    "    return rate\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(title):\n",
    "    file = open(title,\"r\",encoding = 'utf-8')\n",
    "\n",
    "    article = file.read()\n",
    "\n",
    "    cp = seg_sent(article)\n",
    "    \n",
    "    result = model.predict([cp])\n",
    "    output = open('file_sa.txt','w')\n",
    "    if result == 0:\n",
    "        print (\"这是一篇负面新闻\")\n",
    "        output.write(\"这是一篇负面新闻\")\n",
    "    else:\n",
    "        print(\"这是一篇正面新闻\")\n",
    "        output.write(\"这是一篇正面新闻\")\n",
    "    print('负面值:\\t\\t','正面值:')\n",
    "    rate = model.predict_proba([cp])\n",
    "    print(rate)\n",
    "    output.write(\"负面值2：\"+str(rate[0][0])+\" 正面值2： \"+str(rate[0][1]))\n",
    "    return rate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     import sys\n",
    "#     import tkinter as tk\n",
    "#     from tkinter import filedialog\n",
    "\n",
    "#     root = tk.Tk()\n",
    "#     root.withdraw()\n",
    "\n",
    "#     file_path = filedialog.askopenfilename()\n",
    "#     main(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['安徽', '新', '力', '金融', '股份', '有限公司', '关于', '子公司', '涉及', '业务', '诉讼', '的', '公告']\n",
      "[[ 0.85459419  0.14540581]]\n",
      "['天夏', '智慧', ':', '关于', '因', '控股', '股东', '质押', '股票', '触及', '平仓', '线', '的', '停牌', '公告']\n",
      "[[ 0.94727046  0.05272954]]\n",
      "['高正', '信息', ':', '关于', '控股', '子公司', '完成', '工商登记', '的', '公告']\n",
      "[[ 0.48664962  0.51335038]]\n",
      "['关于', '控股', '股东', '提高', '盈利', '增长']\n",
      "[[ 0.52083839  0.47916161]]\n",
      "['公司', '的', '公告', '发撒']\n",
      "[[ 0.78772801  0.21227199]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.78772801,  0.21227199]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = \"安徽新力金融股份有限公司关于子公司涉及业务诉讼的公告\"\n",
    "seg_list = list(jieba.cut(article, cut_all = False))\n",
    "print(seg_list)\n",
    "predictForConttent(article)\n",
    "\n",
    "\n",
    "article = \"天夏智慧:关于因控股股东质押股票触及平仓线的停牌公告\"\n",
    "seg_list = list(jieba.cut(article, cut_all = False))\n",
    "print(seg_list)\n",
    "predictForConttent(article)\n",
    "\n",
    "\n",
    "article = \"高正信息:关于控股子公司完成工商登记的公告\"\n",
    "seg_list = list(jieba.cut(article, cut_all = False))\n",
    "print(seg_list)\n",
    "predictForConttent(article)\n",
    "\n",
    "article = \"关于控股股东提高盈利增长\"\n",
    "seg_list = list(jieba.cut(article, cut_all = False))\n",
    "print(seg_list)\n",
    "predictForConttent(article)\n",
    "\n",
    "\n",
    "article = \"公司的公告发撒\"\n",
    "seg_list = list(jieba.cut(article, cut_all = False))\n",
    "print(seg_list)\n",
    "predictForConttent(article)\n",
    "\n",
    "\n",
    "# a = main(\"/Users/daichanglin/Desktop/igoldenbeta/robotSVN/robot/robot-parent/python/sa/test/rp1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(\"/Users/daichanglin/Desktop/igoldenbeta/robotSVN/robot/robot-parent/python/sa/test/p1\",\n",
    "#             \"r\",encoding = 'utf-8')\n",
    "# article = file.read()\n",
    "# predictForConttent(article)\n",
    "\n",
    "# file = open(\"/Users/daichanglin/Desktop/igoldenbeta/robotSVN/robot/robot-parent/python/sa/test/p2\",\n",
    "#             \"r\",encoding = 'utf-8')\n",
    "# article = file.read()\n",
    "# predictForConttent(article)\n",
    "\n",
    "# # file = open(\"/Users/daichanglin/Desktop/igoldenbeta/robotSVN/robot/robot-parent/python/sa/test/rp3\",\n",
    "# #             \"r\",encoding = 'utf-8')\n",
    "# # article = file.read()\n",
    "# # predictForConttent(article)\n",
    "\n",
    "\n",
    "# file = open(\"/Users/daichanglin/Desktop/igoldenbeta/robotSVN/robot/robot-parent/python/sa/test/rp1\",\n",
    "#             \"r\",encoding = 'utf-8')\n",
    "# article = file.read()\n",
    "# predictForConttent(article)\n",
    "\n",
    "# file = open(\"/Users/daichanglin/Desktop/igoldenbeta/robotSVN/robot/robot-parent/python/sa/test/rp2\",\n",
    "#             \"r\",encoding = 'utf-8')\n",
    "# article = file.read()\n",
    "# predictForConttent(article)\n",
    "\n",
    "# file = open(\"/Users/daichanglin/Desktop/igoldenbeta/robotSVN/robot/robot-parent/python/sa/test/rp3\",\n",
    "#             \"r\",encoding = 'utf-8')\n",
    "# article = file.read()\n",
    "# predictForConttent(article)\n",
    "\n",
    "\n",
    "# file = open(\"/Users/daichanglin/Desktop/igoldenbeta/robotSVN/robot/robot-parent/python/sa/test/rp4\",\n",
    "#             \"r\",encoding = 'utf-8')\n",
    "# article = file.read()\n",
    "# predictForConttent(article)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# //model1\n",
    "# [[ 0.45633987  0.54366013]]\n",
    "# [[ 0.75958081  0.24041919]]\n",
    "# [[ 0.53703431  0.46296569]]\n",
    "# [[ 0.50166667  0.49833333]]\n",
    "# [[ 0.433125  0.566875]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
